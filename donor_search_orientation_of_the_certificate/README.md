# Определение ориентации медицинской справки на фотографии

## Введение
Заказчик - DonorSearch -  занимается развитием донорства в стране. Для этого есть платформа DonorSearch.org - где для доноров доступны бонусная программа, игрофикация пути донора и многое другое. Важной является проверка честности доноров и корректности внесенных донаций. Подтверждение производится по справке установленной формы (№405), такую справку донор получает в центре крови.

## Задачи проекта
- Исследовать существующие подходы к решению задачи;
- Выбор готовой или обучение собственной модели компьютерного зрения для определения ориентации изображения;
- Подготовка скриптов для препроцессинга изображения, инференса модели и постпроцессинга изображения;
- Тестирование модели, определение метрик;
- Создание микросервиса FastAPI для последующей интеграции в продукт заказчика.

## Стек технологий

- **FastAPI** — фреймворк для разработки API.
- **PyTorch** — для работы с предобученной моделью компьютерного зрения.
- **Sklearn** — для рассчета метрик.
- **Docker и Docker-Compose** — для контейнеризации и управления сервисами.
- **Pillow (PIL)** — для обработки изображений.

## Заказчик
DonorSearch
Некоммерческая организация по поиску доноров крови


## Исходные данные
Набор изображений из 173 справок в разной ориентации. Имеются целевые фотографии справок, а так же дополнительные.


## Требования

- Рассчитана Accuracy для многоклассовой классификации;
- Построены ROC-кривые и матрицы ошибок для наилучшей из моделей;
- Формат входных данных - путь к изображению;
- Формат выходных данных - np.array или Pillow.Image (либи любой другой вариант, итоговый вариант озвучит заказчик);
- Количество классов классификатора - 4 (поворот на 0, 90, 180 или 270 градусов);
- Инференс - на CPU.

### **Инструкции по использованию:**
1. Необходимо склонировать репозиторий:

   ```bash
   git clone https://github.com/yakashin/portfolio/blood_search_orientation_of_the_certificate.git
   cd blood_search_orientation_of_the_certificate
```

2. Запустите проект с помощью Docker Compose:

Для запуска всех сервисов используйте следующую команду:

   ```bash
docker-compose up --build
```

Это создаст и запустит все необходимые контейнеры, включая FastAPI-приложение и любые другие зависимости.

3. Доступ к приложению:

Приложение будет доступно по адресу: http://localhost:8000

4. Документация API:

Вы можете воспользоваться интерактивной документацией FastAPI (Swagger UI) по адресу: http://localhost:8000/docs


### Метрика и условия:
- Скорость обработки кадра должна быть не более 1000 мс. 
- Метрика оценки модели – Accuracy.

## Выбор модели

В проекте использовалось предобученные модели с последующим обучении на исходных данных с разной ориентацией (0, 90, 180, 270 градусов):
- ResNet18;
- ResNet34;
- EfficientNet_B0;
- MobileNet V3;
- ShuffleNet V2.

**Результат:**
- дообученная модель CV;
- микросервис написанный в FastAPI+uvicorn;
- docker image с микросервисом.

## Структура репозитория:

| #    | Наименование файла                | Описание   |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1.   | [README.md](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/README.md) | Представлена основная информация по проекту и его результатах   |
| 2.   | [config.py](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/config.py) | Класс, в котором задаются константы и пути к файлам   |
| 3.   | [init_model.py](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/init_model.py) | Класс, который инициализирует работу модели детекции и трекинга объектов и всех функций необходимых для визуализации их работы и расчета метрик   |
| 4.   | [main.py](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/main.py) | Код запуска всех методов имеющихся в классах    |
| 5.   | [requirements.txt](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/requirements.txt) | Список всех библиотек и их версии, необходимых для установки в виртуальной среде для запуска кода проекта   |
| 6.   | [streamlit_yolo.py](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/streamlit_yolo.py) | Веб приложение в стримлит с моделью заказчика YOLA |
| 7.   | [report.md](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/report.md) | Отчёт о проделанной работе |
| 8.   | [Renue_group_5.ipynb](https://github.com/FedorSafonov/tracking-objects-on-a-conveyor-belt/blob/main/Renue_group_5.ipynb) | Тетрадка с ходом исследования |

## Итоги

* **Основные выводы:**  
В ходе исследования выполнено:
- Анализ современных методов определения ориентации объекта на картинке;
- Аугментация изображений в части поворота на 90, 180 и 270 градусов. Итоговое количество изображений увеличилось с 173 до 692;
- Подготовка DataLoader с трансофрмацией изображения в тензор и разбивка на батчи по 32 тензора в каждом. Выполнены отдельные трансформации для тренировочного, валидационного и тестового датасетов;
- Проведен разбор 5 разных моделей: ResNet18, ResNet34, EfficientNet, MobileNet и ShuffleNet. Для каждой нейросети указаны преимущества и недостатки;
- Подготовлены скрипты для загрузки нейросетей, тренировки и тестирования. Все нейросети отлично справились с поставленной задачей, получены следующие результаты при валидации:
  - ResNet18: Inference time per image: 0.1055 seconds, Validation Loss: 0.0733, Accuracy: 0.9712;
  - ResNet34: Inference time per image: 0.1605 seconds, Validation Loss: 0.0515, Accuracy: 0.9904;
  - EfficientNet: Inference time per image: 0.1556 seconds, Validation Loss: 0.0132, Accuracy: 0.9904;
  - ShuffleNet_V2: Inference time per image: 0.0999 seconds, Validation Loss: 0.0169, Accuracy: 0.9904;
  - MobileNet_v3: Inference time per image: 0.0984 seconds, Validation Loss: 0.0134, Accuracy: 0.9904.
- По совокупности показателей выбрана модель EfficientNet, проведено обучение на 120 эпохах, модель сохранена для загрузки в docker container;
- Проведено тестирование модели, построены Матрица спутанности и ROC-AUC кривая. Модель выполнила верно все предсказания и показала отличный результат. 
- Вне отчета написан микросервис на FastAPI с возможностью тестирования в реальном времени;
- Микросервис подготовлен и доступен для развертывания в docker.
 

## Cтатус: 
Завершён.



