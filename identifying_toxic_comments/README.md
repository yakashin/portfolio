# Сопоставление векторов библиотекой FAISS

Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Задача: обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок. 

Требование к результату: модель со значением метрики качества *F1* не меньше 0.75. Для выполнения проекта применена модель *BERT*.

В качестве исходных данных получен кампус английских твитов. Кампус состоит из сырого текста, без удаления стоп слов и символов. Для выполнения задания выбрана языковая модель BERT, которая хорошо работает на сыром тексте и не требует предварительной обработки текста. Единственная необходимая обработка - модель BERT имеет ограничение в 512 символов текста. Выбрана преподготовленная модель BERT 'JungleLee/bert-toxic-comment-classification'. Преимущества модели - для токсичных текстов модель показывает результат лучше базовой модели, а так же сокращение времени подготовки embeddings в 6 раз.

Датасет разделен на тестовую и тренировочную выборку в соотношении 9:1, выявлен дисбаланс классов. Отрицательный класс представлен практически в 9 раз больше положительного. Для борьбы с дисбалансом выбраны методы upsampling и downsampling. Для подбора параметров выбрана модель машинного обучения **LGBM**, так как совмещает в себе скорость и качество предсказания, а метрикой выбора параметров выбрана целевая метрика согласно техническому задания заказчика - **F1-мера**. Для модели подобраны оптимальные гиперпараметры библиотекой Optuna.

После подбора гиперпараметров модель предсказала токсичность текста с результатом **0.890** по метрике F1. Для улучшения предсказания и борьбы с дисбалансом проведен подбор параметров upsampling/downsampling. Для метода upsampling оптимальный множитель редкого класса **n = 1**, что значит отсутсвие улучшения предсказания данным методом. Для downsampling подобрана доля от общего количества частого класса **frac = 0.7**, результат **0.891**. 

Стэк: pandas, numpy, sklearn, torch, BERT, Optuna, catboost, xgboost, tqdm.
